{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e969a6f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline \n",
    "# %config InlineBackend.figure_format = 'retina' ## This is preferable for retina display. \n",
    "\n",
    "import warnings ## importing warnings library. \n",
    "warnings.filterwarnings('ignore') ## Ignore warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4468d324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALP_first</th>\n",
       "      <th>ALP_last</th>\n",
       "      <th>ALT_first</th>\n",
       "      <th>ALT_last</th>\n",
       "      <th>AST_first</th>\n",
       "      <th>AST_last</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin_first</th>\n",
       "      <th>Albumin_last</th>\n",
       "      <th>BUN_first</th>\n",
       "      <th>...</th>\n",
       "      <th>TroponinT_first</th>\n",
       "      <th>TroponinT_last</th>\n",
       "      <th>UrineOutputSum</th>\n",
       "      <th>WBC_first</th>\n",
       "      <th>WBC_last</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Weight_first</th>\n",
       "      <th>Weight_last</th>\n",
       "      <th>pH_first</th>\n",
       "      <th>pH_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>13.3</td>\n",
       "      <td>76.0</td>\n",
       "      <td>80.6</td>\n",
       "      <td>81.6</td>\n",
       "      <td>7.45</td>\n",
       "      <td>7.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>6.2</td>\n",
       "      <td>56.7</td>\n",
       "      <td>56.7</td>\n",
       "      <td>56.7</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.5</td>\n",
       "      <td>7.9</td>\n",
       "      <td>84.6</td>\n",
       "      <td>84.6</td>\n",
       "      <td>84.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ALP_first  ALP_last  ALT_first  ALT_last  AST_first  AST_last   Age  \\\n",
       "0        NaN       NaN        NaN       NaN        NaN       NaN  54.0   \n",
       "1        NaN       NaN        NaN       NaN        NaN       NaN  76.0   \n",
       "2      127.0     105.0       91.0      75.0      235.0     164.0  44.0   \n",
       "3      105.0     105.0       12.0      12.0       15.0      15.0  68.0   \n",
       "4        NaN       NaN        NaN       NaN        NaN       NaN  88.0   \n",
       "\n",
       "   Albumin_first  Albumin_last  BUN_first  ...  TroponinT_first  \\\n",
       "0            NaN           NaN       13.0  ...              NaN   \n",
       "1            NaN           NaN       16.0  ...              NaN   \n",
       "2            2.7           2.3        8.0  ...              NaN   \n",
       "3            4.4           4.4       23.0  ...              NaN   \n",
       "4            3.3           3.3       45.0  ...              NaN   \n",
       "\n",
       "   TroponinT_last  UrineOutputSum  WBC_first  WBC_last  Weight  Weight_first  \\\n",
       "0             NaN             NaN       11.2       9.4     NaN           NaN   \n",
       "1             NaN             5.0        7.4      13.3    76.0          80.6   \n",
       "2             NaN            14.0        4.2       6.2    56.7          56.7   \n",
       "3             NaN             NaN       11.5       7.9    84.6          84.6   \n",
       "4             NaN             NaN        3.8       4.8     NaN           NaN   \n",
       "\n",
       "   Weight_last  pH_first  pH_last  \n",
       "0          NaN       NaN      NaN  \n",
       "1         81.6      7.45     7.37  \n",
       "2         56.7      7.51     7.47  \n",
       "3         84.6       NaN      NaN  \n",
       "4          NaN       NaN      NaN  \n",
       "\n",
       "[5 rows x 114 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_PATH = \"./data/Train.csv\"\n",
    "Y_PATH = \"./data/y.csv\"\n",
    "\n",
    "X = pd.read_csv(X_PATH)\n",
    "y = pd.read_csv(Y_PATH).values.ravel()\n",
    "\n",
    "print(len(X))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4a089c",
   "metadata": {},
   "source": [
    "### Adding the missing ICUType column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74ea6ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"MICU\"] = (~(X[\"CCU\"].astype(bool) | X[\"CSRU\"].astype(bool) | X[\"SICU\"].astype(bool))).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e99d84c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(577, 874, 1481, 1068)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X[\"CCU\"] == 1).sum(), (X[\"CSRU\"] == 1).sum(), (X[\"MICU\"] == 1).sum(), (X[\"SICU\"] == 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1b8bcf",
   "metadata": {},
   "source": [
    "### Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a59d06b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6311625a",
   "metadata": {},
   "source": [
    "## Print Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f050ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, auc, roc_curve, matthews_corrcoef\n",
    "\n",
    "def print_metrics(y_true, y_pred):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)    \n",
    "\n",
    "    print(f\"Confusion Matrix\")\n",
    "    print(f\"{conf_matrix}\\n\")\n",
    "    print(f\"Accuracy: {(tp + tn)/(tp + tn + fn + fp)}\")\n",
    "    print(f\"Precision: {tp / (tp + fp)}\")\n",
    "    print(f\"Recall: {tp / (tp + fn)}\")\n",
    "    print(f\"AUC score: {auc(fpr, tpr)}\")\n",
    "    print(f\"MCC score: {mcc}\")\n",
    "    print(f\"F1-Score: {(tp)/(tp+(fp+fn)/2)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58db8c2",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f0c623",
   "metadata": {},
   "source": [
    "## 1. Drop columns with too many missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eac30e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_threshold = 0.5\n",
    "\n",
    "count = X_train.isna().sum()\n",
    "cols_to_drop = X_train.columns[count / len(X) > drop_threshold]\n",
    "\n",
    "X_train = X_train.drop(columns=cols_to_drop)\n",
    "X_test = X_test.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bf3a1b",
   "metadata": {},
   "source": [
    "## 2. Imputing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8675a05",
   "metadata": {},
   "source": [
    "We implement the ``` get_imputer ``` function to quickly get the desired imputer handling method during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd5ab4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "def get_imputer(name: str, kwargs = None):\n",
    "    if name == \"median\":        \n",
    "        return SimpleImputer(strategy = \"median\")\n",
    "    elif name == \"most-frequent\":\n",
    "        return SimpleImputer(strategy = \"most-frequent\")\n",
    "    elif name == \"knn\":\n",
    "        #TODO kwargs\n",
    "        return KNNImputer()\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dc2919",
   "metadata": {},
   "source": [
    "### Standard Imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8463635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = get_imputer(\"median\")\n",
    "\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33944df6",
   "metadata": {},
   "source": [
    "### Imputing based on ```IcuType``` feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d23889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IcuType_impute(strategy: str, X_train, X_test = None, return_imputers: bool = False, **kwargs):\n",
    "    imputers = {\"CCU\": get_imputer(strategy, kwargs), \"CSRU\": get_imputer(strategy, kwargs), \n",
    "                \"MICU\": get_imputer(strategy, kwargs), \"SICU\": get_imputer(strategy, kwargs)}\n",
    "    \n",
    "    X_train = X_train.copy()\n",
    "    \n",
    "    if X_test is not None:\n",
    "        X_test = X_test.copy()\n",
    "    \n",
    "    for type, imputer in imputers.items():\n",
    "        X_train.loc[X_train[type] == 1, :] = imputer.fit_transform(X_train.loc[X_train[type] == 1, :])\n",
    "        X_test.loc[X_test[type] == 1, :] = imputer.transform(X_test.loc[X_test[type] == 1, :])\n",
    "    \n",
    "    ret_val = X_train\n",
    "    if X_test is not None:\n",
    "        ret_val = (ret_val, X_test)\n",
    "    if return_imputers:\n",
    "        ret_val = (*ret_val, imputers)    \n",
    "    \n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a668c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = IcuType_impute(\"median\", X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782964b7",
   "metadata": {},
   "source": [
    "## 3. Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206ea961",
   "metadata": {},
   "source": [
    "Let's see how much the data is imbalanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc3df4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class1: 3446\n",
      "Class2: 554\n"
     ]
    }
   ],
   "source": [
    "print(f\"Class1: {np.sum(y == 0)}\")\n",
    "print(f\"Class2: {np.sum(y == 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffce9832",
   "metadata": {},
   "source": [
    "We implement the ``` get_imbalance_handler ``` function to quickly get the desired imbalance handling method during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "947a67e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Imbalanced_learn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mImbalanced_learn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler, SMOTE, BorderlineSMOTE\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_imbalance_handler\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m, random_state: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomOverSampler\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Imbalanced_learn'"
     ]
    }
   ],
   "source": [
    "from Imbalanced_learn.over_sampling import RandomOverSampler, SMOTE, BorderlineSMOTE\n",
    "\n",
    "def get_imbalance_handler(name: str, random_state: int = 42):\n",
    "    if name == \"RandomOverSampler\":\n",
    "        return RandomOverSampler(random_state=random_state)\n",
    "    elif name == \"SMOTE\":\n",
    "        return SMOTE(random_state=42)\n",
    "    elif name == \"BorderlineSMOTE\":\n",
    "        return BorderlineSMOTE(random_state=random_state)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a6a2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalance_handler = get_imbalance_handler(\"BorderlineSMOTE\")\n",
    "\n",
    "X_train, y_train = imbalance_handler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f138970f",
   "metadata": {},
   "source": [
    "Let's see the class counts now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f10b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Class1: {np.sum(y == 0)}\")\n",
    "print(f\"Class2: {np.sum(y == 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d55f1b0",
   "metadata": {},
   "source": [
    "## 4. Removing Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f720885",
   "metadata": {},
   "source": [
    "Taken from https://www.kaggle.com/code/jonaspalucibarbosa/removing-outliers-within-a-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b295dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomSampler_IQR (X, y):\n",
    "    \n",
    "    features = X.columns\n",
    "    df = X.copy()\n",
    "    df['Outcome'] = y\n",
    "    \n",
    "    indices = [x for x in df.index]    \n",
    "    out_indexlist = []\n",
    "        \n",
    "    for col in features:\n",
    "       \n",
    "        #Using nanpercentile instead of percentile because of nan values\n",
    "        Q1 = np.nanpercentile(df[col], 25.)\n",
    "        Q3 = np.nanpercentile(df[col], 75.)\n",
    "        \n",
    "        cut_off = (Q3 - Q1) * 1.5\n",
    "        upper, lower = Q3 + cut_off, Q1 - cut_off\n",
    "                \n",
    "        outliers_index = df[col][(df[col] < lower) | (df[col] > upper)].index.tolist()\n",
    "        outliers = df[col][(df[col] < lower) | (df[col] > upper)].values        \n",
    "        out_indexlist.extend(outliers_index)\n",
    "        \n",
    "    #using set to remove duplicates\n",
    "    out_indexlist = list(set(out_indexlist))\n",
    "    \n",
    "    clean_data = np.setdiff1d(indices,out_indexlist)\n",
    "\n",
    "    return X.loc[clean_data].values, y[clean_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce04c26c",
   "metadata": {},
   "source": [
    "## 5. Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c4a5b3",
   "metadata": {},
   "source": [
    "We implement the ``` get_scaler ``` function to quickly get the desired feature scaling method during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b57bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "def get_scaler(name: str):\n",
    "    if name == \"MinMaxScaler\":\n",
    "        return MinMaxScaler()\n",
    "    elif name == \"StandardScaler\":\n",
    "        return StandardScaler()\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fa00b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = get_scaler(\"StandardScaler\")\n",
    "\n",
    "X_train = scaler.fit_transform(X_train) \n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a58210",
   "metadata": {},
   "source": [
    "# AdaBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc2e911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab83a65",
   "metadata": {},
   "source": [
    "## Evaluation on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff1374",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=300, algorithm=\"SAMME.R\", random_state = 42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Train Set Results: \")\n",
    "print_metrics(y_train, y_train_pred)\n",
    "\n",
    "print(\"Test Set Results: \")\n",
    "print_metrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcf441f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
