{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e969a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_PATH = \"./data/Train.csv\"\n",
    "Y_PATH = \"./data/y.csv\"\n",
    "\n",
    "X = pd.read_csv(X_PATH)\n",
    "y = pd.read_csv(Y_PATH).values.ravel()\n",
    "\n",
    "print(len(X))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b3deba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_index = X.index\n",
    "X_cols = X.columns \n",
    "X = X.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bf3a1b",
   "metadata": {},
   "source": [
    "## 1. Imputing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea66edb",
   "metadata": {},
   "source": [
    "### Method1: Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5ab4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy = \"median\")\n",
    "param_grid = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85f5781",
   "metadata": {},
   "source": [
    "### Method2: KNNImpute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb8c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782964b7",
   "metadata": {},
   "source": [
    "## 2. Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206ea961",
   "metadata": {},
   "source": [
    "Let's see how much the data is imbalanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc9ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Class1: {np.sum(y == 0)}\")\n",
    "print(f\"Class2: {np.sum(y == 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a2c6d6",
   "metadata": {},
   "source": [
    "### Method1: Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c4b4d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "imbalance_handler = RandomOverSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec889095",
   "metadata": {},
   "source": [
    "### Method2: SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7dccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "imbalance_handler = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0512df",
   "metadata": {},
   "source": [
    "### Method3: BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd7967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "imbalance_handler = BorderlineSMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d55f1b0",
   "metadata": {},
   "source": [
    "## 3. Removing Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f720885",
   "metadata": {},
   "source": [
    "Taken from https://www.kaggle.com/code/jonaspalucibarbosa/removing-outliers-within-a-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b295dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomSampler_IQR (X, y):\n",
    "    \n",
    "    features = X.columns\n",
    "    df = X.copy()\n",
    "    df['Outcome'] = y\n",
    "    \n",
    "    indices = [x for x in df.index]    \n",
    "    out_indexlist = []\n",
    "        \n",
    "    for col in features:\n",
    "       \n",
    "        #Using nanpercentile instead of percentile because of nan values\n",
    "        Q1 = np.nanpercentile(df[col], 25.)\n",
    "        Q3 = np.nanpercentile(df[col], 75.)\n",
    "        \n",
    "        cut_off = (Q3 - Q1) * 1.5\n",
    "        upper, lower = Q3 + cut_off, Q1 - cut_off\n",
    "                \n",
    "        outliers_index = df[col][(df[col] < lower) | (df[col] > upper)].index.tolist()\n",
    "        outliers = df[col][(df[col] < lower) | (df[col] > upper)].values        \n",
    "        out_indexlist.extend(outliers_index)\n",
    "        \n",
    "    #using set to remove duplicates\n",
    "    out_indexlist = list(set(out_indexlist))\n",
    "    \n",
    "    clean_data = np.setdiff1d(indices,out_indexlist)\n",
    "\n",
    "    return X.loc[clean_data].values, y[clean_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40036a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = CustomSampler_IQR(pd.DataFrame(X, index = X_index, columns = X_cols), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db63cf4",
   "metadata": {},
   "source": [
    "The amount of samples left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b451b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa64c61",
   "metadata": {},
   "source": [
    "Class balance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bac8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(y == 0))\n",
    "print(np.sum(y == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce04c26c",
   "metadata": {},
   "source": [
    "## 4. Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c4a5b3",
   "metadata": {},
   "source": [
    "### Method1: MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b57bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0305366f",
   "metadata": {},
   "source": [
    "### Method2: StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85550b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58d9cc8",
   "metadata": {},
   "source": [
    "## Baseline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7ff774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, auc, roc_curve, matthews_corrcoef\n",
    "\n",
    "model = LogisticRegression(penalty = \"l2\", max_iter = 500)\n",
    "kf = KFold(n_splits=20, shuffle=True, random_state=42)\n",
    "scores = np.zeros(kf.get_n_splits(X))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    X_train, y_train= X[train_index], y[train_index]\n",
    "    X_test, y_test = X[test_index], y[test_index] \n",
    "    \n",
    "    X_train, y_train = imbalance_handler.fit_resample(X_train, y_train)\n",
    "    X_train = scaler.fit_transform(imputer.fit_transform(X_train))\n",
    "    X_test = scaler.transform(imputer.transform(X_test))    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, model.predict(X_test))\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, model.predict(X_test))\n",
    "    scores[i] = model.score(X_test, y_test)\n",
    "    \n",
    "    print(f\"Fold {i + 1}: \\n\")\n",
    "    print(f\"Confusion Matrix\")\n",
    "    print(f\"{conf_matrix}\\n\")\n",
    "    print(f\"Accuracy: {(tp + tn)/(tp + tn + fn + fp)}\")\n",
    "    print(f\"Precision: {tp / (tp + fp)}\")\n",
    "    print(f\"Recall: {tp / (tp + fn)}\")\n",
    "    print(f\"AUC score: {auc(fpr, tpr)}\")\n",
    "    print(f\"MCC score: {matthews_corrcoef(y_test, model.predict(X_test))}\")\n",
    "    print(f\"F1-Score: {(tp)/(tp+(fp+fn)/2)}\\n\")\n",
    "    print(scores[i])\n",
    "#     fpr = fp/(fp+tn)\n",
    "#     tpr = tp/(tp+fn)\n",
    "    \n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c7ce8c",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f627b1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scoring_metric = \"f1\"\n",
    "param_grid = {\"imputer__n_neighbors\" : [1, 3, 7], \"imputer__weights\": [\"uniform\", \"distance\"] }\n",
    "\n",
    "model = LogisticRegression(penalty = \"l2\", max_iter = 500)\n",
    "pipe = Pipeline([(\"imputer\", imputer), ('scaler', StandardScaler()), ('model', model)])\n",
    "grid = GridSearchCV(pipe, param_grid, scoring = scoring_metric, verbose = 3)\n",
    "grid.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
